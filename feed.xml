<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="https://debjyoti0891.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://debjyoti0891.github.io/" rel="alternate" type="text/html" /><updated>2022-11-02T14:53:26+00:00</updated><id>https://debjyoti0891.github.io/feed.xml</id><title type="html">Debjyoti Bhattacharjee</title><subtitle>Snapshots of ideas and things that piqued my interest. The website has information primarily focused on my research in computer architecture and systems, including high performance computing, emerging technologies, alongside design space exploration. </subtitle><author><name>Debjyoti Bhattacharjee</name><email>debjyoti [dot] bhattacharjee [at] imec [dot] be</email></author><entry><title type="html">Stumbling with Spike</title><link href="https://debjyoti0891.github.io/riscv/modelling/architecture/iss/2022/10/31/spike.html" rel="alternate" type="text/html" title="Stumbling with Spike" /><published>2022-10-31T08:00:00+00:00</published><updated>2022-10-31T08:00:00+00:00</updated><id>https://debjyoti0891.github.io/riscv/modelling/architecture/iss/2022/10/31/spike</id><content type="html" xml:base="https://debjyoti0891.github.io/riscv/modelling/architecture/iss/2022/10/31/spike.html">&lt;p&gt;&lt;strong&gt;Assumption&lt;/strong&gt;: The &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;riscv64-unknown-linux-gnu&lt;/code&gt; toolchain is already built and availble on the PATH.&lt;/p&gt;

&lt;h2 id=&quot;install-dtc&quot;&gt;Install &lt;a href=&quot;https://git.launchpad.net/ubuntu/+source/device-tree-compiler/?h=applied/debian/sid&quot;&gt;DTC&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The device tree compiler (dtc) executable is a requirement for spike. It can be compiled from scratch.
The binary should be available in the PATH environment variable.&lt;/p&gt;

&lt;h2 id=&quot;install-proxykernel&quot;&gt;Install &lt;a href=&quot;https://github.com/riscv-software-src/riscv-pk&quot;&gt;ProxyKernel&lt;/a&gt;&lt;/h2&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir build
cd build 
../configure --prefix=&amp;lt;install prefix&amp;gt; --host=riscv64-unknown-linux-gnu
make -j all
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;note&quot;&gt;Note&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;If you try to build in the root of the repository, the output file for &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pk&lt;/code&gt; does not get generated, as there is a directory with the same name. Hence, using a build folder helps!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;install-spike&quot;&gt;Install &lt;a href=&quot;https://github.com/riscv-software-src/riscv-isa-sim&quot;&gt;spike&lt;/a&gt;.&lt;/h2&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./configure --prefix=&amp;lt;install prefix&amp;gt; --with-boost=&amp;lt;path to boost root&amp;gt; --enable-commitlog --with-isa=RV64IMAFDCP 
make -j all
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;note-1&quot;&gt;Note:&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;In my specific installation, Boost libraries could not be found
  even after setting appropriate LD_LIBRARY_PATH. Explictly specifiying the path solved the issue.&lt;/li&gt;
  &lt;li&gt;Take a look at the output of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./configure --help&lt;/code&gt; to find options that might be relevant. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--enable-commitlog&lt;/code&gt; was something that was relevant for me.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;spike-execution&quot;&gt;Spike Execution&lt;/h2&gt;

&lt;h3 id=&quot;creating-the-executable&quot;&gt;Creating the executable&lt;/h3&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;riscv64-unknown-elf-gcc -o hello hello.c&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;actual-execution&quot;&gt;Actual execution&lt;/h3&gt;
&lt;p&gt;To run spike with a baremetal program and log the commits to a file:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;spike  -m 1G --log-commits --log=spike_log.txt $(\which pk) hello 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name>Debjyoti Bhattacharjee</name><email>debjyoti [dot] bhattacharjee [at] imec [dot] be</email></author><category term="riscv" /><category term="modelling" /><category term="architecture" /><category term="iss" /><category term="modelling" /><category term="architecture" /><category term="micro" /><category term="architecture" /><summary type="html">Assumption: The riscv64-unknown-linux-gnu toolchain is already built and availble on the PATH. Install DTC The device tree compiler (dtc) executable is a requirement for spike. It can be compiled from scratch. The binary should be available in the PATH environment variable. Install ProxyKernel mkdir build cd build ../configure --prefix=&amp;lt;install prefix&amp;gt; --host=riscv64-unknown-linux-gnu make -j all make install Note If you try to build in the root of the repository, the output file for pk does not get generated, as there is a directory with the same name. Hence, using a build folder helps! Install spike. ./configure --prefix=&amp;lt;install prefix&amp;gt; --with-boost=&amp;lt;path to boost root&amp;gt; --enable-commitlog --with-isa=RV64IMAFDCP make -j all make install Note: In my specific installation, Boost libraries could not be found even after setting appropriate LD_LIBRARY_PATH. Explictly specifiying the path solved the issue. Take a look at the output of ./configure --help to find options that might be relevant. For example, --enable-commitlog was something that was relevant for me. Spike Execution Creating the executable riscv64-unknown-elf-gcc -o hello hello.c Actual execution To run spike with a baremetal program and log the commits to a file: spike -m 1G --log-commits --log=spike_log.txt $(\which pk) hello</summary></entry><entry><title type="html">A Fast and Furious Introduction to Sparta</title><link href="https://debjyoti0891.github.io/sparta/modelling/architecture/2021/11/07/sparta.html" rel="alternate" type="text/html" title="A Fast and Furious Introduction to Sparta" /><published>2021-11-07T08:00:00+00:00</published><updated>2021-11-07T08:00:00+00:00</updated><id>https://debjyoti0891.github.io/sparta/modelling/architecture/2021/11/07/sparta</id><content type="html" xml:base="https://debjyoti0891.github.io/sparta/modelling/architecture/2021/11/07/sparta.html">&lt;p&gt;&lt;a href=&quot;https://sparcians.github.io/map/index.html&quot;&gt;Sparta&lt;/a&gt; is a modeling framework that can be used for a variety of architecture (or otherwise) modelling work. In this blog post, I present 
an introduction to the basic bells and whistles of the framework. The entire tutorial is available via &lt;a href=&quot;https://github.com/debjyoti0891/sparta-simplified&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;usecase&quot;&gt;Usecase&lt;/h3&gt;
&lt;p&gt;We extend the basic &lt;a href=&quot;https://sparcians.github.io/map/skeleton_example.html&quot;&gt;example&lt;/a&gt; to introduce a new &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparta::Unit&lt;/code&gt; Pipe. 
Producer sends data to a Pipe. Pipe receives data and forwards this to a consumer. Consumer signals the Pipe that
data is received. In turn, Pipe signals the producer that data has been received and the cycle continues.&lt;/p&gt;

&lt;h3 id=&quot;pipe-definition-pipehpp&quot;&gt;Pipe definition (Pipe.hpp)&lt;/h3&gt;

&lt;p&gt;Each sparta unit should have a ParameterSet (subclass of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparta::ParameterSet&lt;/code&gt; ). With each parameter, there can be a validation method attached,
to check if valid values were set to the parameter and a name of the unit as well.&lt;/p&gt;

&lt;p&gt;For the Pipe, we consider 4 ports — two data ports and two signal ports.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    sparta::DataOutPort&amp;lt;uint32_t&amp;gt; pipe_out_port_{&amp;amp;unit_port_set_, &quot;pipe_out_port&quot;};
    sparta::DataInPort&amp;lt;uint32_t&amp;gt;  pipe_in_port_ {&amp;amp;unit_port_set_, &quot;pipe_in_port&quot;, sparta::SchedulingPhase::PortUpdate, 1};
    sparta::SignalInPort          pipe_go_port_ {&amp;amp;unit_port_set_, &quot;pipe_go_port&quot;};
    sparta::SignalOutPort         pipe_go_producer_port_ {&amp;amp;unit_port_set_, &quot;pipe_go_producer_port&quot;};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The DataInPort receives the data from the producer and sends it to the consumer
using the DataOutPort. Similarly, it receives acknowledgement of the receipt by the consumer using the SignalInPort,
which it passes along to the producer using the SignalOutPort.&lt;/p&gt;

&lt;p&gt;Corresponding to each input port, we can define a handler to perform some action on the received data.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
    // Pipe receive handler
    // receive the data from the producer 
    void receiveData_(const uint32_t &amp;amp; dat);

    // receive signal from the consumer and send a singal to the producer
    void receiveSignal_();

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;We can also define events, that will be triggered after a specified duration on scheduling. For example,
we define a event to delay signalling the producer,  after a signal is received from the consumer. In this case,
delay is 5 cycles and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sendData_&lt;/code&gt; is called as its handler.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    // An event to be scheduled in the sparta::SchedulingPhase::Tick
    // phase if data is received
    sparta::Event&amp;lt;&amp;gt; event_do_some_work_{&amp;amp;unit_event_set_, &quot;do_work_event&quot;,
                                        CREATE_SPARTA_HANDLER(Pipe, sendData_),5};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Statistics can be measured quite easily.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Stats
    sparta::Counter num_processed_{&amp;amp;unit_stat_set_, &quot;num_processed_&quot;,
                                  &quot;Number of items produced&quot;, sparta::Counter::COUNT_NORMAL};
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;To use such a counter, a simple &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;++num_processed_&lt;/code&gt; would suffice.&lt;/p&gt;

&lt;p&gt;Finally, loggers can be set up per Unit.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sparta::log::MessageSource pipe_info_;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pipe-implementation-pipecpp&quot;&gt;Pipe implementation (Pipe.cpp)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Start by defining the name of the Unit&lt;/li&gt;
  &lt;li&gt;The handler methods are tied to the ports in the constructor.
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  // Register a handler when the producer sends a data
  pipe_in_port_.registerConsumerHandler(CREATE_SPARTA_HANDLER_WITH_DATA(Pipe, receiveData_, uint32_t));

  // Register a go-handler when the consumer sends a go request
  pipe_go_port_.registerConsumerHandler(CREATE_SPARTA_HANDLER(Pipe, receiveSignal_));
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
    &lt;p&gt;These methods are called when the data is received at the port.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;We schedule the event inside &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;receiveData_&lt;/code&gt;.
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;event_do_some_work_.schedule();&lt;/code&gt;
  This would trigger &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sendData_&lt;/code&gt; after 5 cycles.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;building-the-simulator-tree-stagesimhppcpp&quot;&gt;Building the simulator tree (StageSim{.hpp,.cpp})&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StageSim.hpp&lt;/code&gt; is the top level module definition.&lt;/li&gt;
  &lt;li&gt;In &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;StageSim.cpp&lt;/code&gt;, a bunch of setup needs to be done, in order to build the simulator tree.
    &lt;ul&gt;
      &lt;li&gt;In the constructor, the units and the corresponding parameter sets are made available.
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;getResourceSet()-&amp;gt;addResourceFactory&amp;lt;sparta::ResourceFactory&amp;lt;Pipe, Pipe::PipeParameterSet&amp;gt;&amp;gt;();&lt;/code&gt;&lt;/li&gt;
      &lt;li&gt;The destructor is relatively simple.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;buildTree_&lt;/code&gt; is one of the important things. Basically, each node is created as a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ResourceTreeNode&lt;/code&gt;
  and added to the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;to_delete_&lt;/code&gt; vector. Reading the parameters is performed and the constructor is called using these parameters.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;configureTree_&lt;/code&gt; is not used in the current context.&lt;/li&gt;
      &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;bindTree_&lt;/code&gt; is used to connect the different ports! An example is
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;// bind pipe to the producer
  sparta::bind(root_tree_node-&amp;gt;getChildAs&amp;lt;sparta::Port&amp;gt;(nodeName.str() + &quot;.ports.producer_out_port&quot;),
             root_tree_node-&amp;gt;getChildAs&amp;lt;sparta::Port&amp;gt;(&quot;pipe.ports.pipe_in_port&quot;));
 &lt;/code&gt;
  It can be observed that the port names are hierarchical. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pipe.ports.pipe_in_port&lt;/code&gt; : &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pipe&lt;/code&gt; is the unit, under which
  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ports&lt;/code&gt; is the set of ports and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pipe_in_port&lt;/code&gt; is the name of the port.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;command-line-simulator-setup-main_3scpp&quot;&gt;Command line simulator setup (main_3s.cpp)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Not much changes were made to the original example, except the following.
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;   // Create the simulator object for population -- does not
      // instantiate nor run it.
      sparta::Scheduler scheduler;
      StageSim sim(scheduler, be_noisy);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Now, we are ready to run the simulation
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  cls.populateSimulation(&amp;amp;sim);
  cls.runSimulator(&amp;amp;sim);
  cls.postProcess(&amp;amp;sim);
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;running-the-example&quot;&gt;Running the example&lt;/h3&gt;

&lt;p&gt;In the current environment, the following modules were available.
Currently Loaded Modulefiles:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; 1) GCCcore/10.3.0                   5) numactl/2.0.14-GCCcore-10.3.0      9) hwloc/2.4.1-GCCcore-10.3.0      13) libfabric/1.12.1-GCCcore-10.3.0  17) FlexiBLAS/3.0.4-GCC-10.3.0      21) foss/2021a                      25) Tcl/8.6.11-GCCcore-10.3.0     29) RapidJSON/1.1.0-GCCcore-10.3.0  33) cmake-3.17.5  
 2) zlib/1.2.11-GCCcore-10.3.0       6) XZ/5.2.5-GCCcore-10.3.0           10) OpenSSL/1.1                     14) PMIx/3.2.3-GCCcore-10.3.0        18) gompi/2021a                     22) yaml-cpp-0.6.2                  26) SQLite/3.35.4-GCCcore-10.3.0  30) bzip2/1.0.8-GCCcore-10.3.0      
 3) binutils/2.36.1-GCCcore-10.3.0   7) libxml2/2.9.10-GCCcore-10.3.0     11) libevent/2.1.12-GCCcore-10.3.0  15) OpenMPI/4.1.1-GCC-10.3.0         19) FFTW/3.3.9-gompi-2021a          23) ncurses/6.2-GCCcore-10.3.0      27) Szip/2.1.1-GCCcore-10.3.0     31) GMP/6.2.1-GCCcore-10.3.0        
 4) GCC/10.3.0                       8) libpciaccess/0.16-GCCcore-10.3.0  12) UCX/1.10.0-GCCcore-10.3.0       16) OpenBLAS/0.3.15-GCC-10.3.0       20) ScaLAPACK/2.1.0-gompi-2021a-fb  24) libreadline/8.1-GCCcore-10.3.0  28) HDF5/1.10.7-gompi-2021a       32) boost-1.77.0   ```
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;To build the simulator,&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; mkdir build
 cd build
 cmake ..
 make sparta_3stage
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Sparta has a ton of options, which can be viewed as follows:
&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparta_3stage --help&lt;/code&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;To see the &lt;strong&gt;simulation tree&lt;/strong&gt;,&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sparta_3stage --show-tree&lt;/code&gt;&lt;/p&gt;

    &lt;p&gt;This is a relatively simple way to see which ports are connected to what.&lt;/p&gt;
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  top : &amp;lt;top (root)&amp;gt; (privacy: 0)
  +-descendant_attached : &amp;lt;top.descendant_attached name:&quot;descendant_attached&quot; datat:(sparta::TreeNode)  observers:1 posted:55&amp;gt; (privacy: 0)
  +-consumer : &amp;lt;top.consumer resource: &quot;consumer&quot;&amp;gt; (privacy: 0)
  | +-params : &amp;lt;top.consumer.params 1 params&amp;gt; {builtin} (privacy: 0)
  | | +-num_producers : [&amp;lt;top.consumer.params.num_producers tags:[SPARTA_Parameter]&amp;gt;]&amp;lt;param uint32_t num_producers=1, def=1, write=0 read: 1 ignored: 0&amp;gt; (privacy: 0)
  | +-ports : &amp;lt;top.consumer.ports&amp;gt; (privacy: 0)
  | | +-consumer_in_port : [bound to] {pipe_out_port (top.pipe.ports.pipe_out_port)} (privacy: 0)
  | | | +-events : &amp;lt;top.consumer.ports.consumer_in_port.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | | | +-consumer_in_port_forward_event : &amp;lt;top.consumer.ports.consumer_in_port.events.consumer_in_port_forward_event&amp;gt; (privacy: 0)
  | | +-producer0_go_port : [bound to] {pipe_go_port (top.pipe.ports.pipe_go_port)} (privacy: 0)
  | +-events : &amp;lt;top.consumer.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | +-ev_data_arrived : &amp;lt;top.consumer.events.ev_data_arrived&amp;gt; (privacy: 0)
  | +-stats : &amp;lt;top.consumer.stats 0 stats, 1 counters&amp;gt; {builtin} (privacy: 0)
  | | +-num_consumed : &amp;lt;top.consumer.stats.num_consumed val:100 normal vis:100000000&amp;gt; (privacy: 0)
  | +-? : &amp;lt;top.consumer:log_msg_src cat:&quot;info&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[0])  (privacy: 0)
  | +-? : &amp;lt;top.consumer:log_msg_src cat:&quot;warning&quot; observed:true msgs:0&amp;gt; (_sparta_log_msg_source_[1])  (privacy: 0)
  | +-? : &amp;lt;top.consumer:log_msg_src cat:&quot;debug&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[2])  (privacy: 0)
  | +-? : &amp;lt;top.consumer:log_msg_src cat:&quot;info&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[3])  (privacy: 0)
  +-pipe : &amp;lt;top.pipe resource: &quot;pipe&quot;&amp;gt; (privacy: 0)
  | +-params : &amp;lt;top.pipe.params 0 params&amp;gt; {builtin} (privacy: 0)
  | +-ports : &amp;lt;top.pipe.ports&amp;gt; (privacy: 0)
  | | +-pipe_out_port : [bound to] {consumer_in_port (top.consumer.ports.consumer_in_port)} (privacy: 0)
  | | +-pipe_in_port : [bound to] {producer_out_port (top.producer0.ports.producer_out_port)} (privacy: 0)
  | | | +-events : &amp;lt;top.pipe.ports.pipe_in_port.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | | | +-pipe_in_port_forward_event : &amp;lt;top.pipe.ports.pipe_in_port.events.pipe_in_port_forward_event&amp;gt; (privacy: 0)
  | | +-pipe_go_port : [bound to] {producer0_go_port (top.consumer.ports.producer0_go_port)} (privacy: 0)
  | | | +-events : &amp;lt;top.pipe.ports.pipe_go_port.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | | | +-pipe_go_port_forward_event : &amp;lt;top.pipe.ports.pipe_go_port.events.pipe_go_port_forward_event&amp;gt; (privacy: 0)
  | | +-pipe_go_producer_port : [bound to] {producer_go_port (top.producer0.ports.producer_go_port)} (privacy: 0)
  | +-events : &amp;lt;top.pipe.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | +-do_work_event : &amp;lt;top.pipe.events.do_work_event&amp;gt; (privacy: 0)
  | +-stats : &amp;lt;top.pipe.stats 0 stats, 1 counters&amp;gt; {builtin} (privacy: 0)
  | | +-num_processed_ : &amp;lt;top.pipe.stats.num_processed_ val:101 normal vis:100000000&amp;gt; (privacy: 0)
  | +-? : &amp;lt;top.pipe:log_msg_src cat:&quot;info&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[0])  (privacy: 0)
  | +-? : &amp;lt;top.pipe:log_msg_src cat:&quot;warning&quot; observed:true msgs:0&amp;gt; (_sparta_log_msg_source_[1])  (privacy: 0)
  | +-? : &amp;lt;top.pipe:log_msg_src cat:&quot;debug&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[2])  (privacy: 0)
  | +-? : &amp;lt;top.pipe:log_msg_src cat:&quot;info&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[3])  (privacy: 0)
  +-producer0 : &amp;lt;top.producer0 resource: &quot;producer&quot;&amp;gt; (producer[0])  (privacy: 0)
  | +-params : &amp;lt;top.producer0.params 3 params&amp;gt; {builtin} (privacy: 0)
  | | +-max_ints_to_send : [&amp;lt;top.producer0.params.max_ints_to_send tags:[SPARTA_Parameter]&amp;gt;]&amp;lt;param uint32_t max_ints_to_send=100, def=100, write=0 read: 1 ignored: 0&amp;gt; (privacy: 0)
  | | +-test_param : [&amp;lt;top.producer0.params.test_param tags:[SPARTA_Parameter]&amp;gt;]&amp;lt;param uint32_t test_param=1, def=0, write=1 read: 1 ignored: 0 VOLATILE&amp;gt; (privacy: 0)
  | | +-arch_override_test_param : [&amp;lt;top.producer0.params.arch_override_test_param tags:[SPARTA_Parameter]&amp;gt;]&amp;lt;param std::string arch_override_test_param=reset_in_constructor, def=arch_override_default_value, write=1 read: 0 ignored: 1&amp;gt; (privacy: 0)
  | +-ports : &amp;lt;top.producer0.ports&amp;gt; (privacy: 0)
  | | +-producer_out_port : [bound to] {pipe_in_port (top.pipe.ports.pipe_in_port)} (privacy: 0)
  | | +-producer_go_port : [bound to] {pipe_go_producer_port (top.pipe.ports.pipe_go_producer_port)} (privacy: 0)
  | | | +-events : &amp;lt;top.producer0.ports.producer_go_port.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | | | +-producer_go_port_forward_event : &amp;lt;top.producer0.ports.producer_go_port.events.producer_go_port_forward_event&amp;gt; (privacy: 0)
  | +-events : &amp;lt;top.producer0.events 1 events&amp;gt; {builtin} (privacy: 0)
  | | +-ev_producing_event : &amp;lt;top.producer0.events.ev_producing_event&amp;gt; (privacy: 0)
  | +-stats : &amp;lt;top.producer0.stats 0 stats, 1 counters&amp;gt; {builtin} (privacy: 0)
  | | +-num_produced : &amp;lt;top.producer0.stats.num_produced val:100 normal vis:100000000&amp;gt; (privacy: 0)
  | +-? : &amp;lt;top.producer0:log_msg_src cat:&quot;info&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[0])  (privacy: 0)
  | +-? : &amp;lt;top.producer0:log_msg_src cat:&quot;warning&quot; observed:true msgs:1&amp;gt; (_sparta_log_msg_source_[1])  (privacy: 0)
  | +-? : &amp;lt;top.producer0:log_msg_src cat:&quot;debug&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[2])  (privacy: 0)
  | +-? : &amp;lt;top.producer0:log_msg_src cat:&quot;info&quot; observed:false msgs:0&amp;gt; (_sparta_log_msg_source_[3])  (privacy: 0)
  +-sparta_expression_trigger_fired : &amp;lt;top.sparta_expression_trigger_fired name:&quot;sparta_expression_trigger_fired&quot; datat:(std::__cxx11::basic_string&amp;lt;char, std::char_traits&amp;lt;char&amp;gt;, std::allocator&amp;lt;char&amp;gt; &amp;gt;)  observers:0 posted:0&amp;gt; (privacy: 0)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;To generate an html report, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./sparta_3stage --report-all output.html html&lt;/code&gt; . The report format could also be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;yaml&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Selective logging can be done. For example to view logs related to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pipe&lt;/code&gt;,&lt;/p&gt;

    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt; ./sparta_3stage -l top.pipe info pipe_info.txt&lt;/code&gt;
  This would dump the information in a log file, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pipe_info.txt&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;A list of command line usage scenarios is already documented in the main (documentation](https://sparcians.github.io/map/core_example.html) of Sparta.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sparta Docs&lt;/strong&gt; : &lt;a href=&quot;https://sparcians.github.io/map/index.html&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tutorial Code&lt;/strong&gt;: &lt;a href=&quot;https://github.com/debjyoti0891/sparta-simplified&quot;&gt;[Github  link]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Debjyoti Bhattacharjee</name><email>debjyoti [dot] bhattacharjee [at] imec [dot] be</email></author><category term="sparta" /><category term="modelling" /><category term="architecture" /><category term="modelling" /><category term="architecture" /><category term="micro-architecture" /><summary type="html">Sparta is a modeling framework that can be used for a variety of architecture (or otherwise) modelling work. In this blog post, I present an introduction to the basic bells and whistles of the framework. The entire tutorial is available via Github.</summary></entry><entry><title type="html">Semantically Organizing Images</title><link href="https://debjyoti0891.github.io/graph/learning/rdf/images/2021/07/10/rdf.html" rel="alternate" type="text/html" title="Semantically Organizing Images" /><published>2021-07-10T08:00:00+00:00</published><updated>2021-07-10T08:00:00+00:00</updated><id>https://debjyoti0891.github.io/graph/learning/rdf/images/2021/07/10/rdf</id><content type="html" xml:base="https://debjyoti0891.github.io/graph/learning/rdf/images/2021/07/10/rdf.html">&lt;figure class=&quot;quote&quot;&gt;
  &lt;blockquote&gt;
    Take care of all your memories. For you cannot relive them. 
  &lt;/blockquote&gt;
  &lt;figcaption&gt;
    &amp;mdash; Bob Dylan 
    &lt;!-- &lt;cite&gt;Mental models&lt;/cite&gt;   --&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;My collection of images have grown to monstrous scales (more than 600GB) and continues to grow everyday.
The primary culprit being my trigger happy nature, whenever I go out my camera (Nikon D7200). Given my
rather laid back nature to post process the images and categorize them neatly in folders, my collection currently
stands fragmented amidst a chaotic mix of folders spread across multiple hard-disks, without 
any labels in a majority of cases. With this problem in mind, I started planning a “programmatic” way to get 
out of this mess and to take care of the memories!&lt;/p&gt;

&lt;p&gt;With Python as my ally, I started to see which libraries could be used to get started. Turns out &lt;a href=&quot;https://exiftool.org/&quot;&gt;Exiftool&lt;/a&gt; 
is a very handy and mature tool to look at the EXIF data of images and it also has a python interface. Using this 
as a baseline, I built a relatively straight forward script to bring images from multiple locations into a single folder. 
Thereafter, using Exiftool to extract all the meta data, the images are organized sorted by year. Under each year, events are separately put in a folder. 
An event is a day which has &amp;gt;= threshold images. If consecutive days have events, then they are merged into a single event.
The entire script is available on &lt;a href=&quot;https://github.com/debjyoti0891/utilities/tree/master/copy_images&quot;&gt;Github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Organizing images in the chronologically named folders solves only a part of the problem. These are still image dumps, but not memories such as the ones 
offered by &lt;a href=&quot;https://www.facebook.com/help/1056848067697293/&quot;&gt;Facebook&lt;/a&gt;, &lt;a href=&quot;https://support.google.com/photos/answer/9454489?hl=en&amp;amp;co=GENIE.Platform%3DAndroid&quot;&gt;Google Photos&lt;/a&gt;, etc.
This is where my interest for &lt;a href=&quot;https://en.wikipedia.org/wiki/Semantic_network&quot;&gt;semantic networks&lt;/a&gt; comes into the picture. Simply put, a semantic network is a knowledge representation structure that represents semantic relations between concepts in a network. 
Given the fact pictures have multiple entities and a ton of metadata, a semantic network would be useful to navigate images or find images of interest. For example, a query could be to &lt;em&gt;find all pictures with person A and B&lt;/em&gt;. 
Of course, detecting faces present in the images and tagging them with a name would be indeed needed before a semantic network could be built. Tools powered by AI such as &lt;a href=&quot;https://pypi.org/project/deepface/&quot;&gt;Deepface&lt;/a&gt; could be readily used.&lt;/p&gt;

&lt;p&gt;Neo4j is a graph data database, which can be used for storing the semantic network. In order to actually build a semantic network, I started digging into Neo4j RDF and Semantics &lt;a href=&quot;https://neo4j.com/labs/neosemantics/&quot;&gt;toolkit&lt;/a&gt;.  In the 
context of representing the records, &lt;a href=&quot;https://www.w3.org/RDF/&quot;&gt;Resource Description Framework (RDF)&lt;/a&gt; came into the picture. RDF is a standard model for data interchange across the web and used extensively apparently. RDF uses XML representation
for defining relationships of the form &lt;em&gt;subject-&amp;gt;predicate-&amp;gt;object&lt;/em&gt;, which is called a &lt;em&gt;triple&lt;/em&gt;. These RDF records can be directly imported into the graph database and then queried for efficiently navigating all
the images. There is a nicely presented &lt;a href=&quot;http://www.linkeddatatools.com/semantic-web-basics&quot;&gt;tutorial&lt;/a&gt; on the topic. As a next step, I plan to build RDF entires for the entire image dump that I have and hopefully have 
a better way to navigate the memories.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Code&lt;/strong&gt; : Preliminary code for organizing images. &lt;a href=&quot;https://github.com/debjyoti0891/utilities/tree/master/copy_images&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Good tutorial&lt;/strong&gt;: This tutorial provides a relatively detailed introduction to RDF &lt;a href=&quot;http://www.linkeddatatools.com/semantic-web-basics&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Exiftool&lt;/strong&gt;: &lt;a href=&quot;https://exiftool.org/&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deepface&lt;/strong&gt;: &lt;a href=&quot;ttps://pypi.org/project/deepface/&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Debjyoti Bhattacharjee</name><email>debjyoti [dot] bhattacharjee [at] imec [dot] be</email></author><category term="graph" /><category term="learning" /><category term="RDF" /><category term="images" /><category term="graph" /><category term="inference" /><category term="neo4j" /><category term="RDF" /><category term="image-processing" /><summary type="html">Take care of all your memories. For you cannot relive them. &amp;mdash; Bob Dylan My collection of images have grown to monstrous scales (more than 600GB) and continues to grow everyday. The primary culprit being my trigger happy nature, whenever I go out my camera (Nikon D7200). Given my rather laid back nature to post process the images and categorize them neatly in folders, my collection currently stands fragmented amidst a chaotic mix of folders spread across multiple hard-disks, without any labels in a majority of cases. With this problem in mind, I started planning a “programmatic” way to get out of this mess and to take care of the memories!</summary></entry><entry><title type="html">Code Generation with TVM</title><link href="https://debjyoti0891.github.io/machine/learning/tvm/2021/04/30/tvm-getting-started.html" rel="alternate" type="text/html" title="Code Generation with TVM" /><published>2021-04-30T23:32:56+00:00</published><updated>2021-04-30T23:32:56+00:00</updated><id>https://debjyoti0891.github.io/machine/learning/tvm/2021/04/30/tvm-getting%20started</id><content type="html" xml:base="https://debjyoti0891.github.io/machine/learning/tvm/2021/04/30/tvm-getting-started.html">&lt;p&gt;&lt;a href=&quot;https://tvm.apache.org/&quot;&gt;Apache TVM&lt;/a&gt; is yet another compiler framework (&lt;a href=&quot;https://github.com/ONNC/onnc&quot;&gt;ONNC&lt;/a&gt;, &lt;a href=&quot;https://mlir.llvm.org/&quot;&gt;MLIR&lt;/a&gt;, etc.) for machine learning workloads targeted at supporting variety of hardware backends. It supports “Just in Time compilation” for the supported backends. It represents the workloads using “Relay” program, which 
can be then lowered to “&lt;a href=&quot;https://tvm.apache.org/docs/api/python/ir.html#tvm.ir.Attrs.list_field_info&quot;&gt;TVM IR&lt;/a&gt;” and scheduled for execution.&lt;/p&gt;

&lt;p&gt;I started to look at the &lt;a href=&quot;https://tvm.apache.org/2020/07/15/how-to-bring-your-own-codegen-to-tvm&quot;&gt;tutorial&lt;/a&gt; for code generation using &lt;a href=&quot;https://github.com/oneapi-src/oneDNN&quot;&gt;DNNL&lt;/a&gt;. The tutorial provides a relatively comprehensive guide towards 
TVM with a custom code generator, which emits JSON for certain Relay operators marked for the specific code generation backend (in this case “dnnl”).&lt;/p&gt;

&lt;p&gt;By simply enabling the DNNL codegen in the config.cmake and compiling tvm, it is possible to generate the json from a model using the following piece of code.&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mod = relay.transform.AnnotateTarget([&quot;dnnl&quot;])(mod)
mod = relay.transform.MergeCompilerRegions()(mod)
mod = relay.transform.PartitionGraph()(mod)
graph_json, lib, params = relay.build(mod, target='llvm')
print('Graph json:', graph_json)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In the first step, the operators supported by the backend are annotated, which are then merged. The relay graph is partitioned and using the “build” step, the code is generated. For the operators which are not supported by the code generator, these would be executed in TVM. The generated lib includes the host module and the execution modules for the part that cannot be offloaded to the custom backend accelerator. The host module will invoke the accelerator module in runtime when it executes a graph node that is annotated for the accelerator. Currently, TVM does not support ahead of time compilation, which would allow generation of executable at compile time itself, which made TVM unsuitable for my current work.&lt;/p&gt;

&lt;p&gt;In summary, the framework has a lot of features for optimizing machine learning workloads without a lot of effort. However, it might be a bit complex to get started off with the documentation fragmented over a variety of pages. A relatively good order to look at the tutorials in my opinion is listed below.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Good tutorial&lt;/strong&gt;: This tutorial provides the quickest way to understand the primitives of a relay program. &lt;a href=&quot;http://tvm.d2l.ai/chapter_getting_started/vector_add.html&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;TVM + Cuda&lt;/strong&gt; : A jupyter notebook that shows how to use CUDA as a backend. &lt;a href=&quot;https://github.com/andersy005/tvm-in-action/blob/master/tvm-tutorials/getting-started.ipynb&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Beginner guide&lt;/strong&gt; : This is a good starting point to understand the TVM code base structure. &lt;a href=&quot;https://tvm.apache.org/docs/dev/codebase_walkthrough.html&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Good code gen tutorial&lt;/strong&gt; : The tutorial provides a relatively comprehensive guide towards 
TVM with a custom code generator, which emits codes for certain Relay operators marked for the specific code generation backend.  &lt;a href=&quot;https://tvm.apache.org/2020/07/15/how-to-bring-your-own-codegen-to-tvm&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Available relay passes&lt;/strong&gt;: A number of built-in passes are already provided to optimize the relay graph. However, the passes might emit errors if the input relay graph has custom operators. &lt;a href=&quot;https://tvm.apache.org/docs/api/python/relay/transform.html&quot;&gt;[Link]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Debjyoti Bhattacharjee</name><email>debjyoti [dot] bhattacharjee [at] imec [dot] be</email></author><category term="machine" /><category term="learning" /><category term="TVM" /><category term="ai" /><category term="ml" /><category term="&quot;neural" /><category term="network&quot;" /><category term="tvm" /><category term="compiler" /><summary type="html">Apache TVM is yet another compiler framework (ONNC, MLIR, etc.) for machine learning workloads targeted at supporting variety of hardware backends. It supports “Just in Time compilation” for the supported backends. It represents the workloads using “Relay” program, which can be then lowered to “TVM IR” and scheduled for execution.</summary></entry><entry><title type="html">Welcome to my blog</title><link href="https://debjyoti0891.github.io/eda/2020/03/04/first-post.html" rel="alternate" type="text/html" title="Welcome to my blog" /><published>2020-03-04T16:32:56+00:00</published><updated>2020-03-04T16:32:56+00:00</updated><id>https://debjyoti0891.github.io/eda/2020/03/04/first-post</id><content type="html" xml:base="https://debjyoti0891.github.io/eda/2020/03/04/first-post.html">&lt;p&gt;My keen interest in hardware technologies, coupled with my background in computer science, has driven me to pursue research in the direction of design automation algorithms and tools for architectures, for a variety of technologies. Recently, I am learning about the state-of-the-art in Deep Neural Networks~(NN) and understanding the NN strutures (&lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot; target=&quot;_blank&quot;&gt;Alexnet&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot; target=&quot;_blank&quot;&gt;Resnet&lt;/a&gt;, etc).&lt;/p&gt;

&lt;p&gt;In parallel, I have started using &lt;a href=&quot;https://pytorch.org/&quot;&gt;PyTorch&lt;/a&gt; for implementation of DNNs. For the purpose of designing efficient NN accelerators, the first step is to find a way to extract an exact description of the NN graph. I found out the possiblity of finding the execution traces of the defined NNs using &lt;a href=&quot;https://pytorch.org/docs/stable/jit.html#mixing-tracing-and-scripting&quot;&gt;Torchscript&lt;/a&gt; and then parsing them into a directed graph. However, this is almost an hack! A better alternative was to look at the Open Neural Network Exchange (&lt;a href=&quot;https://onnx.ai/&quot;&gt;ONNX&lt;/a&gt;) format for NNs. Each ONNX model is self contained and can be accessed as a &lt;a href=&quot;#proto&quot;&gt;ProtoBuf&lt;/a&gt; object. PyTorch and most other deep NN frameworks allows models to be directly written to ONNX format, which makes it a common representation to be used for the process of design automation of NN accelerators.&lt;/p&gt;

&lt;p&gt;In the upcoming blogs, expect more details of design automation process for NN accelerators to be unveiled.&lt;/p&gt;

&lt;h3 id=&quot;references&quot;&gt;References&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf&quot; target=&quot;_blank&quot;&gt;ImageNet Classification with Deep ConvolutionalNeural Networks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot; target=&quot;_blank&quot;&gt;Deep Residual Learning for Image Recognition&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/overview&quot; target=&quot;_blank&quot;&gt;Introduction to protocol buffers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>Debjyoti Bhattacharjee</name><email>debjyoti [dot] bhattacharjee [at] imec [dot] be</email></author><category term="eda" /><category term="introduction" /><category term="ai" /><category term="ml" /><category term="eda" /><category term="pytorch" /><summary type="html">My keen interest in hardware technologies, coupled with my background in computer science, has driven me to pursue research in the direction of design automation algorithms and tools for architectures, for a variety of technologies. Recently, I am learning about the state-of-the-art in Deep Neural Networks~(NN) and understanding the NN strutures (Alexnet, Resnet, etc).</summary></entry></feed>